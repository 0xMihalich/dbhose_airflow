to_reader
=========

.. py:method:: PGPackDumper.to_reader(
    query=None,
    table_name=None,
   )

   :param query: SQL-запрос для выборки данных
   :type query: str | None
   :param table_name: Имя таблицы для полной выборки данных
   :type table_name: str | None
   :return: Объект StreamReader для потокового чтения данных в PGPack формате
   :rtype: StreamReader
   :raises PGPackDumperReadError: При ошибках чтения данных

   Создание потока для чтения данных из PostgreSQL/GreenPlum в виде объекта StreamReader с данными в PGPack формате.

**Описание:**

Метод создает объект ``StreamReader``, который предоставляет потоковый доступ
к данным из PostgreSQL/GreenPlum в PGPack формате. Это позволяет обрабатывать большие
объемы данных без загрузки всего результата в память.

``StreamReader`` реализует интерфейс для чтения данных в потоковом режиме и может использоваться
для передачи данных между системами или для последующей обработки в других форматах.

**Ключевые особенности:**

* **Потоковое чтение** - данные читаются по мере необходимости через COPY протокол
* **Минимальное потребление памяти** - не загружает весь результат в память
* **PGPack формат** - данные представлены в оптимизированном бинарном формате
* **Метаданные** - включает информацию о структуре таблицы (колонки, типы данных)
* **Совместимость** - может использоваться с методом ``write_between`` для передачи данных

**Параметры:**

.. list-table:: Параметры метода to_reader
   :widths: 20 30 50
   :header-rows: 1

   * - Параметр
     - Тип
     - Описание
   * - ``query``
     - ``str | None``
     - SQL-запрос для выборки данных. SQL-запрос имеет приоритет, поэтому, в случае передачи обоих параметров, метод проигнорирует указанную таблицу.
       Пример: ``"SELECT * FROM table WHERE condition"``
   * - ``table_name``
     - ``str | None``
     - Имя таблицы для полной выборки всех данных. Используется только если ``query`` не указан. Формат: ``"schema.table"`` или ``"table"``

**Возвращаемое значение:**

Объект ``StreamReader`` с методами для потокового чтения данных.

**Примеры использования:**

.. code-block:: python

    # Пример 1: Потоковое чтение всей таблицы
    from pgpack_dumper import PGPackDumper, PGConnector
    
    connector = PGConnector(host="localhost", port=5432, dbname="mydb")
    dumper = PGPackDumper(connector=connector)
    
    reader = dumper.to_reader(table_name="public.user_logs")
    
    # Пример 2: Чтение данных по запросу с фильтрацией
    query = """
        SELECT user_id, action, timestamp, amount
        FROM sales.transactions 
        WHERE transaction_date = CURRENT_DATE
        ORDER BY timestamp DESC
    """
    
    reader = dumper.to_reader(query=query)

**Обработка ошибок:**

.. code-block:: python

    # Пример 1: Обработка ошибок чтения
    try:
        reader = dumper.to_reader(query="SELECT * FROM nonexistent_table")
        # Ошибка может произойти при создании reader или при попытке чтения
    except PGPackDumperReadError as e:
        print(f"Ошибка чтения: {e}")
        # Возможные причины: таблица не существует, синтаксическая ошибка в запросе,
        # недостаточно прав доступа
    
    # Пример 2: Проверка доступности данных
    try:
        reader = dumper.to_reader(table_name="important.data")
        # Проверка что reader создан успешно
        if reader:
            print("StreamReader успешно создан")
    except Exception as e:
        print(f"Неожиданная ошибка: {e}")

**Сценарии использования StreamReader:**

1. **Потоковая передача данных** - между серверами через ``write_between``
2. **Обработка больших результатов** - когда данные не помещаются в память
3. **Инкрементальная загрузка** - последовательная обработка данных по частям
4. **Промежуточное хранение** - временное хранение данных в потоковом формате
5. **Интеграция с другими системами** - передача данных в совместимые форматы

**Работа с метаданными:**

Метод автоматически сохраняет метаданные в ``self._dbmeta``,
включая информацию о колонках (имена и типы данных).

**Производительность и память:**

* **COPY протокол** - используется для эффективной потоковой передачи
* **Буферизация** - оптимальный размер буфера для сетевой передачи
* **Метаданные кеширование** - метаданные сохраняются для повторного использования
* **Сжатие** - данные могут быть сжаты в соответствии с настройками PGPackDumper

**Методы StreamReader:**

Созданный ``StreamReader`` предоставляет следующие основные методы:
* ``read()`` - чтение данных
* ``to_rows()`` - преобразование в итератор строк
* ``close()`` - закрытие потока и освобождение ресурсов

**Пример использования StreamReader:**

.. code-block:: python

    # Получение StreamReader
    reader = dumper.to_reader(table_name="public.large_table")
    
    try:
        # Потоковая обработка данных
        for chunk in reader.to_rows():
            # Обработка каждой порции данных
            process_data(chunk)
    finally:
        # Важно закрыть reader для освобождения ресурсов
        reader.close()
    
    # Использование с write_between
    other_dumper.write_between(
        table_dest="backup.table_copy",
        dumper_src=reader  # Передача reader как источника
    )

**Примечания:**

* Объект ``StreamReader`` требует закрытия после использования (метод ``close()``)
* Данные читаются последовательно, повторное чтение невозможно
* Метаданные доступны через ``dumper._dbmeta`` после вызова метода
* Для работы с очень большими таблицами рекомендуется использовать фильтрацию в запросах

**См. также:**

- :doc:`write_between` - Передача данных с использованием StreamReader
- :class:`StreamReader` - Документация по классу StreamReader
- :doc:`read_dump` - Альтернативный способ получения данных в файл
- :doc:`metadata_reader` - Извлечение метаданных таблицы
